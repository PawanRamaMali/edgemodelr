# Modern 2024 Models Example
# This example showcases the newest small language models available in edgemodelr

library(edgemodelr)

# Function to showcase a model
showcase_model <- function(model_name, prompt = "Write a short poem about AI.") {
  cat("\n" , rep("=", 60), "\n")
  cat("Testing Model:", model_name, "\n")
  cat(rep("=", 60), "\n")
  
  tryCatch({
    # Quick setup for the model
    cat("Setting up", model_name, "...\n")
    setup <- edge_quick_setup(model_name)
    
    if (is.null(setup$context)) {
      cat("âŒ Failed to load", model_name, "\n")
      return(NULL)
    }
    
    ctx <- setup$context
    cat("âœ… Successfully loaded", model_name, "\n")
    cat("Model path:", setup$model_path, "\n\n")
    
    # Generate response
    cat("Prompt:", prompt, "\n")
    cat("Response:\n")
    response <- edge_completion(ctx, prompt, n_predict = 100)
    cat(response, "\n\n")
    
    # Clean up
    edge_free_model(ctx)
    cat("âœ… Model cleaned up\n")
    
    return(response)
    
  }, error = function(e) {
    cat("âŒ Error with", model_name, ":", e$message, "\n")
    return(NULL)
  })
}

# Main demonstration function
main <- function() {
  cat("ðŸš€ Modern 2024 Models Showcase\n")
  cat("Demonstrating the latest small language models\n\n")
  
  # Show available models
  cat("ðŸ“‹ Available Models:\n")
  models <- edge_list_models()
  for (i in 1:nrow(models)) {
    cat(sprintf("  %s - %s (%s)\n", 
                models$name[i], 
                models$use_case[i], 
                models$size[i]))
  }
  
  # Showcase 2024 models
  modern_models <- c("llama3.2-1b", "qwen2.5-1.5b", "phi3.5-mini", "gemma2-2b")
  
  cat("\nðŸŽ¯ Testing Modern 2024 Models:\n")
  
  results <- list()
  
  for (model in modern_models) {
    result <- showcase_model(model, "Explain quantum computing in simple terms.")
    results[[model]] <- result
    Sys.sleep(1)  # Brief pause between models
  }
  
  # Summary
  cat("\nðŸ“Š Summary:\n")
  for (model in names(results)) {
    status <- if (!is.null(results[[model]])) "âœ… Success" else "âŒ Failed"
    cat("  ", model, ":", status, "\n")
  }
  
  cat("\nðŸ’¡ Tips:\n")
  cat("  â€¢ Use 'llama3.2-1b' for mobile/edge applications\n")
  cat("  â€¢ Use 'qwen2.5-1.5b' for multilingual tasks\n") 
  cat("  â€¢ Use 'phi3.5-mini' for reasoning tasks\n")
  cat("  â€¢ Use 'gemma2-2b' for balanced performance\n")
  
  return(results)
}

# Quick test function for a single model
test_llama32 <- function() {
  cat("ðŸ¦™ Quick Llama 3.2 Test\n")
  return(showcase_model("llama3.2-1b", "Hello, how are you?"))
}

# Run the demonstration if called directly
if (interactive()) {
  cat("Run main() to test all 2024 models\n")
  cat("Run test_llama32() for a quick test\n")
} else {
  # Run when sourced
  main()
}