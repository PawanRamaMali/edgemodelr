Package: edgemodelr
Type: Package
Title: Local Large Language Model Inference Engine
Version: 0.1.2
Authors@R: person("Pawan Rama", "Mali", email = "prm@outlook.in", role = c("aut", "cre"))
Author: Pawan Rama Mali [aut, cre]
Maintainer: Pawan Rama Mali <prm@outlook.in>
Description: Enables R users to run large language models locally using 'GGUF' model files
    and the 'llama.cpp' inference engine. Provides a complete R interface for loading models,
    generating text completions, and streaming responses in real-time. Supports local
    inference without requiring cloud APIs or internet connectivity, ensuring complete
    data privacy and control. Based on the 'llama.cpp' project by Georgi Gerganov (2023) <https://github.com/ggml-org/llama.cpp>.
License: MIT + file LICENSE
URL: https://github.com/PawanRamaMali/edgemodelr
BugReports: https://github.com/PawanRamaMali/edgemodelr/issues
Encoding: UTF-8
Depends: R (>= 4.0)
LinkingTo: Rcpp
Imports:
    Rcpp (>= 1.0.0),
    utils,
    tools
Suggests: 
    testthat (>= 3.0.0),
    knitr,
    rmarkdown
SystemRequirements: C++17, GNU make or equivalent for building
Note: Package includes self-contained 'llama.cpp' implementation (~56MB)
  for complete functionality without external dependencies.
Config/testthat/edition: 3
Roxygen: list(markdown = TRUE)
RoxygenNote: 7.3.3
